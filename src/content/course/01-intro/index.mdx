---
title: "Введение в Change Data Capture"
description: "Знакомство с концепцией CDC, основными паттернами и архитектурой Debezium"
order: 1
difficulty: "beginner"
estimatedTime: 45
topics: ["CDC", "Debezium", "Architecture", "Event Streaming"]
---

import { Mermaid } from '../../../components/Mermaid.tsx';

# Введение в Change Data Capture

Change Data Capture (CDC) — это паттерн проектирования, позволяющий отслеживать и захватывать изменения данных в базе данных в реальном времени. Вместо периодического опроса базы данных, CDC использует встроенные механизмы СУБД для получения событий об изменениях.

## Зачем нужен CDC?

CDC решает несколько критических задач в современных распределенных системах:

1. **Синхронизация данных** между различными системами
2. **Построение Event-Driven архитектуры** на основе изменений в БД
3. **Аудит и отслеживание изменений** для compliance требований
4. **Создание материализованных представлений** и аналитических хранилищ

## Архитектура Debezium

Debezium — это платформа для CDC, построенная на Apache Kafka Connect. Она предоставляет коннекторы для различных СУБД и обеспечивает надежную доставку событий изменений.

<Mermaid chart={`
flowchart LR
    DB[(PostgreSQL)]
    DEB[Debezium Connector]
    KAFKA[Apache Kafka]
    CONSUMER1[Consumer 1]
    CONSUMER2[Consumer 2]

    DB -->|WAL| DEB
    DEB -->|CDC Events| KAFKA
    KAFKA --> CONSUMER1
    KAFKA --> CONSUMER2

    style DB fill:#3b82f6
    style DEB fill:#10b981
    style KAFKA fill:#f59e0b
    style CONSUMER1 fill:#8b5cf6
    style CONSUMER2 fill:#8b5cf6
`} client:visible />

## Пример конфигурации коннектора

Базовая конфигурация Debezium коннектора для PostgreSQL:

```json
{
  "name": "postgres-connector",
  "config": {
    "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
    "database.hostname": "localhost",
    "database.port": "5432",
    "database.user": "debezium",
    "database.password": "dbz",
    "database.dbname": "inventory",
    "database.server.name": "dbserver1",
    "table.include.list": "public.customers,public.orders",
    "plugin.name": "pgoutput"
  }
}
```

## SQL: создание пользователя для репликации

Для работы Debezium необходимо создать пользователя с правами на чтение WAL:

```sql
-- Создание пользователя для репликации
CREATE USER debezium WITH REPLICATION PASSWORD 'dbz';

-- Выдача прав на схему и таблицы
GRANT SELECT ON ALL TABLES IN SCHEMA public TO debezium;
GRANT USAGE ON SCHEMA public TO debezium;

-- Включение логической репликации
ALTER SYSTEM SET wal_level = logical;
ALTER SYSTEM SET max_replication_slots = 4;
ALTER SYSTEM SET max_wal_senders = 4;
```

## Python: обработка CDC событий

Пример простого consumer для обработки CDC событий:

```python
from kafka import KafkaConsumer
import json

# Инициализация consumer
consumer = KafkaConsumer(
    'dbserver1.public.customers',
    bootstrap_servers=['localhost:9092'],
    auto_offset_reset='earliest',
    value_deserializer=lambda m: json.loads(m.decode('utf-8'))
)

# Обработка событий
for message in consumer:
    event = message.value

    # Извлечение информации о событии
    operation = event['payload']['op']  # c=create, u=update, d=delete
    before = event['payload']['before']
    after = event['payload']['after']

    print(f"Operation: {operation}")
    if operation in ['c', 'u']:
        print(f"New data: {after}")
    if operation in ['u', 'd']:
        print(f"Old data: {before}")
```

## Последовательность обработки события

<Mermaid chart={`
sequenceDiagram
    participant APP as Application
    participant DB as PostgreSQL
    participant WAL as Write-Ahead Log
    participant DBZ as Debezium
    participant KAFKA as Kafka

    APP->>DB: INSERT customer
    DB->>WAL: Write change
    DB-->>APP: Ack

    DBZ->>WAL: Read changes
    WAL-->>DBZ: Change event
    DBZ->>DBZ: Transform to CDC format
    DBZ->>KAFKA: Publish event
    KAFKA-->>DBZ: Ack

    Note over DBZ,KAFKA: Event stored durably
`} client:visible />

## YAML: Docker Compose для локального окружения

Пример конфигурации для быстрого запуска Debezium локально:

```yaml
version: '3.8'

services:
  postgres:
    image: debezium/postgres:15-alpine
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: inventory
    ports:
      - "5432:5432"
    command:
      - "postgres"
      - "-c"
      - "wal_level=logical"

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  connect:
    image: debezium/connect:2.5
    depends_on:
      - kafka
      - postgres
    ports:
      - "8083:8083"
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_configs
      OFFSET_STORAGE_TOPIC: connect_offsets
      STATUS_STORAGE_TOPIC: connect_statuses
```

## Ключевые концепции

В следующих модулях мы подробно изучим:

- **Connector lifecycle** — жизненный цикл коннектора
- **Snapshot modes** — стратегии создания начального снимка данных
- **Schema evolution** — работа с изменениями схемы
- **Fault tolerance** — механизмы обеспечения отказоустойчивости
- **Performance tuning** — оптимизация производительности

## Домашнее задание

1. Развернуть локальное окружение с помощью Docker Compose
2. Создать тестовую базу данных с таблицей `customers`
3. Настроить Debezium коннектор
4. Выполнить INSERT/UPDATE/DELETE операции и проверить события в Kafka

В следующем уроке мы детально разберем процесс установки и настройки Debezium.

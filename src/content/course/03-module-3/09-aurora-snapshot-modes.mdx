---
title: "Aurora MySQL: –í—ã–±–æ—Ä Snapshot Mode –¥–ª—è CDC"
description: "–ü–æ—á–µ–º—É Aurora MySQL –∑–∞–ø—Ä–µ—â–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏, –∫–∞–∫ –≤—ã–±—Ä–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é snapshot –¥–ª—è —Ç–∞–±–ª–∏—Ü —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤, –∏ –∫–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å backup-based –ø–æ–¥—Ö–æ–¥"
order: 9
difficulty: "intermediate"
estimatedTime: 25
topics: ["aurora-mysql", "debezium", "snapshot", "cdc", "locks"]
prerequisites: ["module-8/08-enhanced-binlog-architecture"]
---

import { Mermaid } from '../../../components/Mermaid.tsx';
import Callout from '../../../components/Callout.tsx';

# Aurora MySQL: –í—ã–±–æ—Ä Snapshot Mode –¥–ª—è CDC

## –ü–æ—á–µ–º—É Aurora —Ç—Ä–µ–±—É–µ—Ç –æ—Å–æ–±–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞

–í –ø—Ä–µ–¥—ã–¥—É—â–µ–º —É—Ä–æ–∫–µ –º—ã –∏–∑—É—á–∏–ª–∏ Enhanced Binlog ‚Äî —É–Ω–∏–∫–∞–ª—å–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É Aurora MySQL –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ binlog production. –¢–µ–ø–µ—Ä—å –º—ã —Å—Ç–æ–ª–∫–Ω–µ–º—Å—è —Å –µ—â–µ –æ–¥–Ω–∏–º **–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–º –æ—Ç–ª–∏—á–∏–µ–º Aurora**: **–∑–∞–ø—Ä–µ—Ç –Ω–∞ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏** –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ snapshot –¥–ª—è Debezium CDC.

### –ß—Ç–æ —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ?

–í Community MySQL Debezium –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `FLUSH TABLES WITH READ LOCK` –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è **–∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ–≥–æ snapshot –≤—Å–µ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö**. Aurora MySQL, –∫–∞–∫ managed service –æ—Ç AWS, **–Ω–µ —Ä–∞–∑—Ä–µ—à–∞–µ—Ç** —ç—Ç–æ—Ç SQL statement –∏–∑ —Å–æ–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –º–Ω–æ–≥–æ–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π —Å—Ä–µ–¥—ã.

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- Debezium –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ **table-level locks** (–±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü)
- –°—Ç—Ä–∞—Ç–µ–≥–∏—è snapshot –∑–∞–≤–∏—Å–∏—Ç –æ—Ç **—Ä–∞–∑–º–µ—Ä–∞ —Ç–∞–±–ª–∏—Ü** –∏ **—Ç–æ–ª–µ—Ä–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∫ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞–º**
- –î–ª—è –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü (500GB+) —Ç—Ä–µ–±—É–µ—Ç—Å—è **backup-based –ø–æ–¥—Ö–æ–¥**

–≠—Ç–æ—Ç —É—Ä–æ–∫ –Ω–∞—É—á–∏—Ç –≤–∞—Å:
- –ü–æ–Ω–∏–º–∞—Ç—å —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É Community MySQL –∏ Aurora –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ snapshot
- –í—ã–±–∏—Ä–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π `snapshot.locking.mode` –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ —Ç–∞–±–ª–∏—Ü
- –†–µ–∞–ª–∏–∑–æ–≤—ã–≤–∞—Ç—å backup-based initial load –¥–ª—è zero-lock —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
- –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å snapshot –∏ troubleshoot –ø—Ä–æ–±–ª–µ–º—ã

## Community MySQL vs Aurora: –†–∞–∑–Ω–∏—Ü–∞ –≤ Lock Scope

### Community MySQL: –ì–ª–æ–±–∞–ª—å–Ω–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ (FLUSH TABLES)

<Mermaid chart={`
graph LR
    D[Debezium Connector]
    D -->|1. FLUSH TABLES WITH READ LOCK| DB[(MySQL Database)]
    DB --> T1[Table 1]
    DB --> T2[Table 2]
    DB --> T3[Table 3]

    style DB fill:#90EE90
    style T1 fill:#FFB6C1
    style T2 fill:#FFB6C1
    style T3 fill:#FFB6C1

    classDef locked fill:#FFB6C1,stroke:#FF0000,stroke-width:3px
`} />

**Community MySQL workflow:**
1. `FLUSH TABLES WITH READ LOCK` ‚Äî **–≤—Å—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö** –±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è –∑–∞–ø–∏—Å–∏
2. –ß—Ç–µ–Ω–∏–µ —Å—Ö–µ–º –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü –ø–æ–¥ –≥–ª–æ–±–∞–ª—å–Ω–æ–π –±–ª–æ–∫–∏—Ä–æ–≤–∫–æ–π
3. –ü–æ–ª—É—á–µ–Ω–∏–µ binlog position (consistent snapshot point)
4. `UNLOCK TABLES` ‚Äî —Å–Ω—è—Ç–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–π –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
5. –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ REPEATABLE READ transaction (–±–µ–∑ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫)

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –ê–±—Å–æ–ª—é—Ç–Ω–∞—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å: –≤—Å–µ —Ç–∞–±–ª–∏—Ü—ã snapshot –≤ –æ–¥–Ω–æ–π —Ç–æ—á–∫–µ –≤—Ä–µ–º–µ–Ω–∏
- –ü—Ä–æ—Å—Ç–æ—Ç–∞: –æ–¥–Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –¥–ª—è –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü

**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:**
- –ë–ª–æ–∫–∏—Ä—É–µ—Ç **–≤—Å—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö** –Ω–∞ –≤—Ä–µ–º—è —á—Ç–µ–Ω–∏—è —Å—Ö–µ–º
- –ú–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–ø—Ä–∏–µ–º–ª–µ–º–æ –¥–ª—è production —Å–∏—Å—Ç–µ–º

### Aurora MySQL: Table-level –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ (LOCK TABLES)

<Mermaid chart={`
graph LR
    D[Debezium Connector]
    D -->|FLUSH TABLES blocked ‚ùå| DB[(Aurora MySQL)]
    D -->|2. Fallback: LOCK TABLES T1| T1[Table 1]
    D -->|3. LOCK TABLES T2| T2[Table 2]
    D -->|4. LOCK TABLES T3| T3[Table 3]
    DB --> T1
    DB --> T2
    DB --> T3

    style DB fill:#FFA500
    style T1 fill:#ADD8E6
    style T2 fill:#ADD8E6
    style T3 fill:#ADD8E6

    classDef partial fill:#ADD8E6,stroke:#0000FF,stroke-width:2px
`} />

**Aurora MySQL workflow:**
1. Debezium –ø—ã—Ç–∞–µ—Ç—Å—è `FLUSH TABLES WITH READ LOCK` ‚Üí **Access Denied error**
2. Debezium –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ fallback: **table-level locks**
3. –î–ª—è –∫–∞–∂–¥–æ–π —Ç–∞–±–ª–∏—Ü—ã –≤ `table.include.list`:
   - `LOCK TABLES <table> READ` ‚Äî –±–ª–æ–∫–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —ç—Ç—É —Ç–∞–±–ª–∏—Ü—É
   - –ß–∏—Ç–∞–µ–º schema (columns, indexes, constraints)
   - `UNLOCK TABLES` ‚Äî —Å–Ω–∏–º–∞–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É
4. –ù–∞—á–∏–Ω–∞–µ–º REPEATABLE READ transaction
5. –ß–∏—Ç–∞–µ–º binlog position
6. –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü (–±–µ–∑ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫)

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –ú–µ–Ω—å—à–µ impact –Ω–∞ production: –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –ø–æ –æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ
- –ù–µ —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–∏–≤–∏–ª–µ–≥–∏–π SUPER (Aurora –Ω–µ –¥–∞–µ—Ç)

**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:**
- –î–ª—è –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –º–æ–∂–µ—Ç –¥–ª–∏—Ç—å—Å—è **–º–∏–Ω—É—Ç—ã**
- Snapshot —Ä–∞–∑–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü –≤ **—Ä–∞–∑–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã –≤—Ä–µ–º–µ–Ω–∏** (–Ω–æ REPEATABLE READ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å binlog position)

<Callout type="warning" title="Aurora –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç fallback">

–í–∞–º **–Ω–µ –Ω—É–∂–Ω–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å** fallback –Ω–∞ table-level locks –≤—Ä—É—á–Ω—É—é. Debezium connector –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:
1. –ü—Ä–æ–±—É–µ—Ç `FLUSH TABLES WITH READ LOCK`
2. –ü–æ–ª—É—á–∞–µ—Ç `ERROR 1227 (42000): Access denied` –æ—Ç Aurora
3. –ü–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ `LOCK TABLES` per-table strategy

–í –ª–æ–≥–∞—Ö connector –≤—ã —É–≤–∏–¥–∏—Ç–µ:
```
INFO: Flush tables with read lock failed, falling back to table-level locks
```

–≠—Ç–æ **–Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ** –¥–ª—è Aurora, –Ω–µ –æ—à–∏–±–∫–∞.

</Callout>

## –ö–∞–∫ Debezium –∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç—Å—è –∫ Aurora: Snapshot Workflow

<Mermaid chart={`
sequenceDiagram
    participant DC as Debezium Connector
    participant AM as Aurora MySQL (writer)
    participant T1 as Table 1 (inventory.customers)
    participant T2 as Table 2 (inventory.orders)

    Note over DC,AM: Phase 1: Detect Aurora (no global lock)
    DC->>AM: FLUSH TABLES WITH READ LOCK
    AM-->>DC: ‚ùå ERROR 1227: Access denied
    DC->>DC: Fallback: use table-level locks

    Note over DC,T1: Phase 2: Lock & read schema (per-table)
    DC->>T1: LOCK TABLES inventory.customers READ
    DC->>T1: Read schema (columns, indexes, PK)
    DC->>T1: UNLOCK TABLES

    DC->>T2: LOCK TABLES inventory.orders READ
    DC->>T2: Read schema
    DC->>T2: UNLOCK TABLES

    Note over DC,AM: Phase 3: Start REPEATABLE READ transaction
    DC->>AM: START TRANSACTION WITH CONSISTENT SNAPSHOT
    DC->>AM: SHOW MASTER STATUS
    AM-->>DC: File=mysql-bin.000003, Position=154

    Note over DC,T1: Phase 4: Read data (no locks held)
    DC->>T1: SELECT * FROM inventory.customers
    DC->>T2: SELECT * FROM inventory.orders

    Note over DC,AM: Phase 5: Commit & resume streaming
    DC->>AM: COMMIT
    DC->>DC: Save offset: mysql-bin.000003:154
    DC->>AM: Resume streaming from saved position
`} />

**–ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã:**

1. **Lock duration = –≤—Ä–µ–º—è —á—Ç–µ–Ω–∏—è schema**
   - –î–ª—è —Ç–∞–±–ª–∏—Ü—ã —Å 10 columns, 2 indexes ‚Üí **—Å–µ–∫—É–Ω–¥—ã**
   - –î–ª—è —Ç–∞–±–ª–∏—Ü—ã —Å 200 columns, 50 indexes ‚Üí **–º–∏–Ω—É—Ç—ã**

2. **Data reading –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫**
   - REPEATABLE READ transaction –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å
   - Binlog position –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞ –≤ –Ω–∞—á–∞–ª–µ transaction
   - –î–∞–∂–µ –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –∏–∑–º–µ–Ω—è—é—Ç—Å—è, snapshot –≤–∏–¥–∏—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–∞ –º–æ–º–µ–Ω—Ç START TRANSACTION

3. **Snapshot —Ä–∞–∑–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü –≤ —Ä–∞–∑–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã**
   - Table 1 schema read: 10:00:00
   - Table 2 schema read: 10:00:05
   - –ù–æ binlog position –æ–¥–Ω–∞: 10:00:10 (START TRANSACTION)
   - –ü–æ—Å–ª–µ snapshot Debezium –¥–æ–≥–æ–Ω–∏—Ç –≤—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å position 10:00:10

## snapshot.locking.mode: –¢—Ä–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫

Debezium MySQL connector –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ç—Ä–∏ —Ä–µ–∂–∏–º–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞–º–∏:

### 1. minimal (default, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤)

**–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç:**
- Table locks **—Ç–æ–ª—å–∫–æ –≤–æ –≤—Ä–µ–º—è —á—Ç–µ–Ω–∏—è schema**
- Data reading —á–µ—Ä–µ–∑ REPEATABLE READ (–±–µ–∑ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫)
- Locks –¥–µ—Ä–∂–∞—Ç—Å—è **—Å–µ–∫—É–Ω–¥—ã –∏–ª–∏ –º–∏–Ω—É—Ç—ã** –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ schema

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
- –¢–∞–±–ª–∏—Ü—ã –º–∞–ª–æ–≥–æ –∏ —Å—Ä–µ–¥–Ω–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ (< 100 GB)
- Production —Å–∏—Å—Ç–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –≤—ã–¥–µ—Ä–∂–∞—Ç—å –∫—Ä–∞—Ç–∫–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
- –ö–æ–≥–¥–∞ –≤–∞–∂–Ω–∞ **–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å snapshot** (–≥–∞—Ä–∞–Ω—Ç–∏—è —Å—Ö–µ–º)

**Connector configuration:**
```json
{
  "snapshot.mode": "initial",
  "snapshot.locking.mode": "minimal"
}
```

**Pros:**
- ‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω–æ: schema —á—Ç–µ–Ω–∏–µ –ø–æ–¥ –±–ª–æ–∫–∏—Ä–æ–≤–∫–æ–π
- ‚úÖ –ë—ã—Å—Ç—Ä–æ: locks –¥–µ—Ä–∂–∞—Ç—Å—è –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è
- ‚úÖ –ì–∞—Ä–∞–Ω—Ç–∏—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ schema

**Cons:**
- ‚ùå –ö—Ä–∞—Ç–∫–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –º–æ–≥—É—Ç –ø–æ–≤–ª–∏—è—Ç—å –Ω–∞ concurrent writes
- ‚ùå –î–ª—è –æ—á–µ–Ω—å —Å–ª–æ–∂–Ω—ã—Ö schema (hundreds of columns) lock duration —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è

### 2. none (zero locks, —Ç—Ä–µ–±—É–µ—Ç schema freeze)

**–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç:**
- **–ù–∏–∫–∞–∫–∏—Ö table locks**
- Schema —á—Ç–µ–Ω–∏–µ –∏ data reading —á–µ—Ä–µ–∑ REPEATABLE READ
- –ü–æ–ª–∞–≥–∞–µ—Ç—Å—è –Ω–∞ MVCC –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
- –û—á–µ–Ω—å –±–æ–ª—å—à–∏–µ —Ç–∞–±–ª–∏—Ü—ã (> 100 GB) —Å **zero lock tolerance**
- –ö–æ–≥–¥–∞ –º–æ–∂–µ—Ç–µ **–≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ schema changes** –≤–æ –≤—Ä–µ–º—è snapshot
- Production —Å–∏—Å—Ç–µ–º—ã —Å –∂–µ—Å—Ç–∫–∏–º–∏ SLA –Ω–∞ latency

**Connector configuration:**
```json
{
  "snapshot.mode": "initial",
  "snapshot.locking.mode": "none"
}
```

<Callout type="danger" title="–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –†–ò–°–ö: Schema change –≤–æ –≤—Ä–µ–º—è snapshot">

**–ß—Ç–æ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç, –µ—Å–ª–∏ ALTER TABLE –≤—ã–ø–æ–ª–Ω–∏—Ç—Å—è –≤–æ –≤—Ä–µ–º—è snapshot?**

–ü—Ä–∏–º–µ—Ä —Å—Ü–µ–Ω–∞—Ä–∏—è:
1. Debezium –Ω–∞—á–∏–Ω–∞–µ—Ç snapshot —Ç–∞–±–ª–∏—Ü—ã `inventory.orders` (10:00:00)
2. –ö—Ç–æ-—Ç–æ –≤—ã–ø–æ–ª–Ω—è–µ—Ç `ALTER TABLE inventory.orders ADD COLUMN priority INT` (10:00:30)
3. Debezium –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —á–∏—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ (10:00:31)

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- Debezium –ø—Ä–æ—á–∏—Ç–∞–ª schema –±–µ–∑ –∫–æ–ª–æ–Ω–∫–∏ `priority` (step 1, no locks)
- Binlog —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–æ–±—ã—Ç–∏—è —Å –∫–æ–ª–æ–Ω–∫–æ–π `priority` (–ø–æ—Å–ª–µ ALTER TABLE)
- **Data inconsistency:** snapshot –∏ binlog stream –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç –ø–æ schema

**–ö–∞–∫ –∏–∑–±–µ–∂–∞—Ç—å:**
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ deployment freeze window –¥–ª—è snapshot
- –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–π—Ç–µ —Å –∫–æ–º–∞–Ω–¥–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏: no DDL during snapshot
- –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `minimal` mode (–ø—Ä–∏–Ω–∏–º–∞–π—Ç–µ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏)

**Verification:**
```sql
-- Monitoring running snapshot
SHOW PROCESSLIST;
-- –ï—Å–ª–∏ –≤–∏–¥–∏—Ç–µ DDL statement –≤–æ –≤—Ä–µ–º—è snapshot ‚Üí STOP DDL immediately
```

</Callout>

**Pros:**
- ‚úÖ –ù–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫ –≤–æ–æ–±—â–µ
- ‚úÖ –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü
- ‚úÖ Minimal impact –Ω–∞ production writes

**Cons:**
- ‚ùå **–û–ø–∞—Å–Ω–æ:** schema change –≤–æ –≤—Ä–µ–º—è snapshot = data corruption
- ‚ùå –¢—Ä–µ–±—É–µ—Ç coordination —Å –∫–æ–º–∞–Ω–¥–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
- ‚ùå –ù–µ –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç schema changes –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏

### 3. extended (–ù–ï —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ Aurora)

**–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç (Community MySQL):**
- `FLUSH TABLES WITH READ LOCK` –Ω–∞ –≤—Ä–µ–º—è snapshot + data reading
- –ë–ª–æ–∫–∏—Ä—É–µ—Ç –≤—Å—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –¥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è snapshot

**–ü–æ—á–µ–º—É –ù–ï —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ Aurora:**
- –¢—Ä–µ–±—É–µ—Ç `FLUSH TABLES WITH READ LOCK` ‚Üí Aurora –Ω–µ —Ä–∞–∑—Ä–µ—à–∞–µ—Ç
- Connector —É–ø–∞–¥–µ—Ç —Å –æ—à–∏–±–∫–æ–π

**Connector configuration (–ù–ï –ò–°–ü–û–õ–¨–ó–£–ô–¢–ï –Ω–∞ Aurora):**
```json
{
  "snapshot.mode": "initial",
  "snapshot.locking.mode": "extended"  // ‚ùå Fails on Aurora
}
```

<Callout type="warning" title="extended mode –Ω–µ —Å–æ–≤–º–µ—Å—Ç–∏–º —Å Aurora">

–ï—Å–ª–∏ –≤—ã –ø–æ–ø—Ä–æ–±—É–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `snapshot.locking.mode=extended` –Ω–∞ Aurora:

```
ERROR: io.debezium.DebeziumException: Could not flush and lock tables:
Access denied; you need (at least one of) the SUPER, RELOAD privilege(s)
for this operation
```

**–†–µ—à–µ–Ω–∏–µ:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `minimal` –∏–ª–∏ `none` mode.

</Callout>

## Decision Matrix: –í—ã–±–æ—Ä snapshot.locking.mode –¥–ª—è Aurora

<table style={{fontSize: '0.9em'}}>
  <thead>
    <tr>
      <th>–†–∞–∑–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã</th>
      <th>Lock Tolerance</th>
      <th>Schema Freeze Possible?</th>
      <th>–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π Mode</th>
      <th>–ü—Ä–∏–º–µ—á–∞–Ω–∏—è</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>&lt; 10 GB</td>
      <td>Normal</td>
      <td>–ù–µ –≤–∞–∂–Ω–æ</td>
      <td><code>minimal</code></td>
      <td>‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π default, locks —Å–Ω–∏–º–∞—é—Ç—Å—è –±—ã—Å—Ç—Ä–æ</td>
    </tr>
    <tr>
      <td>10-100 GB</td>
      <td>Normal</td>
      <td>–ù–µ –≤–∞–∂–Ω–æ</td>
      <td><code>minimal</code></td>
      <td>‚ö†Ô∏è –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å lock duration (—Å–º. —Ä–∞–∑–¥–µ–ª 8)</td>
    </tr>
    <tr>
      <td>10-100 GB</td>
      <td>Zero tolerance</td>
      <td>‚úÖ –î–∞</td>
      <td><code>none</code></td>
      <td>‚ö†Ô∏è –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ: freeze schema changes</td>
    </tr>
    <tr>
      <td>&gt; 100 GB</td>
      <td>Zero tolerance</td>
      <td>‚úÖ –î–∞</td>
      <td><code>none</code></td>
      <td>‚ö†Ô∏è –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ: freeze schema changes</td>
    </tr>
    <tr>
      <td>&gt; 100 GB</td>
      <td>Zero tolerance</td>
      <td>‚ùå –ù–µ—Ç</td>
      <td><strong>Backup-based</strong></td>
      <td>üöÄ –°–º. —Ä–∞–∑–¥–µ–ª 7 (Aurora snapshot + snapshot.mode=never)</td>
    </tr>
    <tr>
      <td>Any</td>
      <td>Cannot freeze schema</td>
      <td>‚ùå –ù–µ—Ç</td>
      <td><code>minimal</code></td>
      <td>‚úÖ –ü—Ä–∏–Ω–∏–º–∞–µ–º –∫—Ä–∞—Ç–∫–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏</td>
    </tr>
    <tr>
      <td>Very large (500GB+)</td>
      <td>Any</td>
      <td>Any</td>
      <td><strong>Backup-based</strong></td>
      <td>üöÄ –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–π –ø–æ–¥—Ö–æ–¥</td>
    </tr>
  </tbody>
</table>

**–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –≤—ã–±–æ—Ä–∞:**

1. **Default –≤—ã–±–æ—Ä:** `minimal` ‚Äî —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è 90% —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
2. **Zero lock tolerance + schema freeze:** `none` ‚Äî advanced use case
3. **Very large tables (500GB+):** Backup-based approach (—Å–º. —Ä–∞–∑–¥–µ–ª 7)
4. **–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:** `extended` –Ω–∞ Aurora (–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç)

## Connector Configuration: –ü—Ä–∏–º–µ—Ä—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤

### –°—Ü–µ–Ω–∞—Ä–∏–π 1: –ú–∞–ª—ã–µ –∏ —Å—Ä–µ–¥–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã (< 100 GB)

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** `snapshot.locking.mode=minimal`

```json
{
  "name": "aurora-mysql-small-tables",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "tasks.max": "1",

    // Aurora writer endpoint (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
    "database.hostname": "my-aurora-cluster.cluster-abc123.us-east-1.rds.amazonaws.com",
    "database.port": "3306",
    "database.user": "debezium",
    "database.password": "${file:/secrets/mysql-password.txt:password}",
    "database.server.id": "184054",

    // Database/table filtering
    "database.include.list": "inventory",
    "table.include.list": "inventory.customers,inventory.orders,inventory.products",

    // Topic naming
    "topic.prefix": "aurora-mysql",

    // Snapshot configuration (Aurora-specific)
    "snapshot.mode": "initial",
    "snapshot.locking.mode": "minimal",  // ‚úÖ Safe default for Aurora

    // Schema history (infinite retention, per Phase 13 decision)
    "schema.history.internal.kafka.bootstrap.servers": "kafka:9092",
    "schema.history.internal.kafka.topic": "schema-history.aurora-mysql",
    "schema.history.internal.store.only.captured.tables.ddl": "true",

    // Heartbeat (detect idle periods)
    "heartbeat.interval.ms": "30000",
    "heartbeat.topics.prefix": "__debezium-heartbeat",

    // Data type handling
    "decimal.handling.mode": "precise",
    "binary.handling.mode": "bytes",
    "time.precision.mode": "adaptive_time_microseconds",

    // Include schema changes in events
    "include.schema.changes": "true",

    // Signal table for incremental snapshots
    "signal.data.collection": "inventory.debezium_signal"
  }
}
```

**Deployment:**
```bash
# Deploy connector via Kafka Connect REST API
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d @aurora-mysql-small-tables.json

# Monitor snapshot progress
curl -s http://localhost:8083/connectors/aurora-mysql-small-tables/status | jq .
```

**Expected behavior:**
- Snapshot –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –≤ —Ç–µ—á–µ–Ω–∏–µ 5-10 —Å–µ–∫—É–Ω–¥
- Table locks –¥–µ—Ä–∂–∞—Ç—Å—è < 1 –º–∏–Ω—É—Ç—ã –Ω–∞ –∫–∞–∂–¥—É—é —Ç–∞–±–ª–∏—Ü—É
- Data reading –±–µ–∑ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫ (–º–æ–∂–µ—Ç –¥–ª–∏—Ç—å—Å—è —á–∞—Å—ã –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü, –Ω–æ –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç writes)

### –°—Ü–µ–Ω–∞—Ä–∏–π 2: –ë–æ–ª—å—à–∏–µ —Ç–∞–±–ª–∏—Ü—ã (> 100 GB), zero lock tolerance

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** `snapshot.locking.mode=none` + schema freeze window

<Callout type="warning" title="–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ preconditions –¥–ª—è none mode">

**–ü–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º `snapshot.locking.mode=none` —É–±–µ–¥–∏—Ç–µ—Å—å:**

1. ‚úÖ **Schema freeze coordinated** —Å –∫–æ–º–∞–Ω–¥–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
2. ‚úÖ **No DDL statements** –ø–ª–∞–Ω–∏—Ä—É—é—Ç—Å—è –≤ —Ç–µ—á–µ–Ω–∏–µ snapshot window
3. ‚úÖ **Monitoring setup** –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è DDL (—Å–º. —Ä–∞–∑–¥–µ–ª 8)
4. ‚úÖ **Rollback plan** –µ—Å–ª–∏ snapshot –ø—Ä–µ—Ä—ã–≤–∞–µ—Ç—Å—è schema change

**–ï—Å–ª–∏ –ù–ï –º–æ–∂–µ—Ç–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å schema freeze:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ backup-based approach (—Ä–∞–∑–¥–µ–ª 7).

</Callout>

```json
{
  "name": "aurora-mysql-large-tables-no-locks",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "tasks.max": "1",

    "database.hostname": "my-aurora-cluster.cluster-abc123.us-east-1.rds.amazonaws.com",
    "database.port": "3306",
    "database.user": "debezium",
    "database.password": "${file:/secrets/mysql-password.txt:password}",
    "database.server.id": "184055",

    "database.include.list": "analytics",
    "table.include.list": "analytics.user_events",  // Very large table (200GB)

    "topic.prefix": "aurora-mysql-analytics",

    // NO LOCKS snapshot mode
    "snapshot.mode": "initial",
    "snapshot.locking.mode": "none",  // ‚ö†Ô∏è Zero locks, –¢–†–ï–ë–£–ï–¢ schema freeze

    // Longer timeout for large table snapshot
    "snapshot.query.timeout.ms": "600000",  // 10 minutes per query

    // Larger binlog buffer for high throughput
    "binlog.buffer.size": "16384",

    // Schema history
    "schema.history.internal.kafka.bootstrap.servers": "kafka:9092",
    "schema.history.internal.kafka.topic": "schema-history.aurora-mysql-analytics",

    // More frequent heartbeats for large tables with infrequent updates
    "heartbeat.interval.ms": "10000",  // 10 seconds

    // Signal table
    "signal.data.collection": "analytics.debezium_signal",

    // Data type handling
    "decimal.handling.mode": "precise",
    "time.precision.mode": "adaptive_time_microseconds"
  }
}
```

**Deployment workflow:**
```bash
# Step 1: Announce schema freeze window
echo "Schema freeze: $(date) - Estimated 6 hours for snapshot"

# Step 2: Deploy connector
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d @aurora-mysql-large-tables.json

# Step 3: Monitor snapshot progress (—Å–º. —Ä–∞–∑–¥–µ–ª 8)
watch -n 10 'curl -s http://localhost:8083/connectors/aurora-mysql-large-tables-no-locks/status | jq .connector.state'

# Step 4: Verify snapshot completion
# Expected log: "Snapshot completed"
docker compose logs debezium-connect | grep "Snapshot completed"

# Step 5: Lift schema freeze
echo "Schema freeze lifted: $(date)"
```

**Expected behavior:**
- **No table locks** at any point
- Snapshot –º–æ–∂–µ—Ç –¥–ª–∏—Ç—å—Å—è **—á–∞—Å—ã** –¥–ª—è –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü
- Production writes **–Ω–µ –±–ª–æ–∫–∏—Ä—É—é—Ç—Å—è**
- **Risk:** –ï—Å–ª–∏ DDL –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤–æ –≤—Ä–µ–º—è snapshot ‚Üí data inconsistency

## Backup-Based Initial Load: –°—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü

–î–ª—è —Ç–∞–±–ª–∏—Ü —Ä–∞–∑–º–µ—Ä–æ–º **500GB+** –¥–∞–∂–µ `snapshot.locking.mode=none` –º–æ–∂–µ—Ç –±—ã—Ç—å **–Ω–µ–ø—Ä–∞–∫—Ç–∏—á–Ω—ã–º**:
- Snapshot —á–µ—Ä–µ–∑ Debezium –º–æ–∂–µ—Ç –¥–ª–∏—Ç—å—Å—è **–¥–Ω–∏**
- –°–µ—Ç–µ–≤–æ–π bandwidth –º–µ–∂–¥—É Aurora –∏ Kafka Connect –æ–≥—Ä–∞–Ω–∏—á–µ–Ω
- Schema freeze –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω

**Backup-based approach** —Ä–µ—à–∞–µ—Ç —ç—Ç–∏ –ø—Ä–æ–±–ª–µ–º—ã:
1. –ò—Å–ø–æ–ª—å–∑—É–µ–º **Aurora DB Cluster Snapshot** –¥–ª—è initial data load
2. Bulk load —á–µ—Ä–µ–∑ JDBC source connector –∏–ª–∏ ETL tool
3. Debezium –∑–∞–ø—É—Å–∫–∞–µ–º —Å `snapshot.mode=never` –æ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ binlog position

### Workflow: Aurora Snapshot ‚Üí Bulk Load ‚Üí Debezium Streaming

<Mermaid chart={`
sequenceDiagram
    participant Ops as Operations Team
    participant AM as Aurora MySQL (writer)
    participant AS as Aurora Snapshot
    participant RC as Restored Cluster
    participant BL as Bulk Load Tool (JDBC/ETL)
    participant K as Kafka
    participant DC as Debezium Connector

    Note over Ops,AM: Phase 1: Capture binlog position
    Ops->>AM: SHOW MASTER STATUS
    AM-->>Ops: File=mysql-bin.000005, Position=154
    Note over Ops: Save: mysql-bin.000005:154

    Note over Ops,AS: Phase 2: Create Aurora snapshot
    Ops->>AM: aws rds create-db-cluster-snapshot
    AM-->>AS: Snapshot created (30-60 min)

    Note over Ops,RC: Phase 3: Restore to temp cluster
    Ops->>AS: aws rds restore-db-cluster-from-snapshot
    AS-->>RC: Restored cluster ready

    Note over RC,BL: Phase 4: Bulk load data to Kafka
    BL->>RC: SELECT * FROM large_table (batches)
    BL->>K: Publish to Kafka topics

    Note over DC,AM: Phase 5: Debezium streaming from binlog
    Ops->>DC: Deploy connector (snapshot.mode=never)
    DC->>AM: Resume from mysql-bin.000005:154
    DC->>K: Stream CDC events

    Note over Ops,RC: Phase 6: Cleanup
    Ops->>RC: Delete restored cluster
`} />

### Step-by-Step Implementation

**Step 1: Capture binlog position –ü–ï–†–ï–î snapshot**

<Callout type="danger" title="–ö–†–ò–¢–ò–ß–ù–û: Binlog position BEFORE snapshot">

–í—ã **–¥–æ–ª–∂–Ω—ã** –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å binlog position **–î–û** —Å–æ–∑–¥–∞–Ω–∏—è Aurora snapshot, –ø–æ—Ç–æ–º—É —á—Ç–æ:

- Aurora snapshot **–Ω–µ –≤–∫–ª—é—á–∞–µ—Ç binlog files** (–æ—Å–æ–±–µ–Ω–Ω–æ —Å Enhanced Binlog)
- –ü–æ—Å–ª–µ restore binlog sequence –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è **—Å .000001** (fresh start)
- Debezium –Ω—É–∂–Ω–∞ **–ø–æ–∑–∏—Ü–∏—è –Ω–∞ production writer**, –Ω–µ –Ω–∞ restored cluster

**–ü–æ—Ä—è–¥–æ–∫:**
1. SHOW MASTER STATUS –Ω–∞ **production writer** ‚Üí save position
2. Create Aurora snapshot
3. Restore snapshot ‚Üí use for bulk load only
4. Debezium connects to **production writer** from saved position (step 1)

</Callout>

```bash
# Connect to Aurora writer (production cluster)
mysql -h my-aurora-cluster.cluster-abc123.us-east-1.rds.amazonaws.com \
  -u admin -p

# Capture current binlog position
mysql> SHOW MASTER STATUS;
# +---------------------------+----------+--------------+------------------+-------------------------------------------+
# | File                      | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set                         |
# +---------------------------+----------+--------------+------------------+-------------------------------------------+
# | mysql-bin-changelog.000005| 154      |              |                  | 3e11fa47-71ca-11e1-9e33-c80aa9429562:1-5  |
# +---------------------------+----------+--------------+------------------+-------------------------------------------+

# SAVE THIS INFORMATION:
# binlog_file = mysql-bin-changelog.000005
# binlog_position = 154
# gtid_set = 3e11fa47-71ca-11e1-9e33-c80aa9429562:1-5
```

**Step 2: –°–æ–∑–¥–∞–Ω–∏–µ Aurora DB Cluster Snapshot**

```bash
# Create snapshot via AWS CLI
aws rds create-db-cluster-snapshot \
  --db-cluster-snapshot-identifier aurora-cdc-baseline-2026-02-01 \
  --db-cluster-identifier my-aurora-cluster \
  --region us-east-1

# Wait for snapshot completion (30-60 minutes for large clusters)
aws rds wait db-cluster-snapshot-available \
  --db-cluster-snapshot-identifier aurora-cdc-baseline-2026-02-01 \
  --region us-east-1

# Verify snapshot status
aws rds describe-db-cluster-snapshots \
  --db-cluster-snapshot-identifier aurora-cdc-baseline-2026-02-01 \
  --query 'DBClusterSnapshots[0].{Status:Status,PercentProgress:PercentProgress}' \
  --region us-east-1
```

**Step 3: Restore snapshot –∫ temporary cluster –¥–ª—è bulk load**

```bash
# Restore snapshot to new Aurora cluster
aws rds restore-db-cluster-from-snapshot \
  --db-cluster-identifier aurora-restore-cdc-temp \
  --snapshot-identifier aurora-cdc-baseline-2026-02-01 \
  --engine aurora-mysql \
  --region us-east-1

# Create instance in restored cluster
aws rds create-db-instance \
  --db-instance-identifier aurora-restore-cdc-temp-instance-1 \
  --db-instance-class db.r5.large \
  --db-cluster-identifier aurora-restore-cdc-temp \
  --engine aurora-mysql \
  --region us-east-1

# Wait for instance availability (10-15 minutes)
aws rds wait db-instance-available \
  --db-instance-identifier aurora-restore-cdc-temp-instance-1 \
  --region us-east-1

# Get restored cluster endpoint
aws rds describe-db-clusters \
  --db-cluster-identifier aurora-restore-cdc-temp \
  --query 'DBClusters[0].Endpoint' \
  --output text
# Output: aurora-restore-cdc-temp.cluster-xyz789.us-east-1.rds.amazonaws.com
```

**Step 4: Bulk load data via JDBC Source Connector**

```json
{
  "name": "jdbc-source-aurora-bulk-load",
  "config": {
    "connector.class": "io.confluent.connect.jdbc.JdbcSourceConnector",
    "tasks.max": "4",

    // Connect to RESTORED cluster (not production)
    "connection.url": "jdbc:mysql://aurora-restore-cdc-temp.cluster-xyz789.us-east-1.rds.amazonaws.com:3306/inventory",
    "connection.user": "admin",
    "connection.password": "${file:/secrets/mysql-password.txt:password}",

    // Bulk mode: read all data
    "mode": "bulk",
    "table.whitelist": "customers,orders,products",

    // Topic naming (match Debezium topic naming)
    "topic.prefix": "aurora-mysql.inventory.",

    // Batch size for performance
    "batch.max.rows": "10000",

    // Poll only once (bulk load, not incremental)
    "poll.interval.ms": "86400000"  // 24 hours (effectively: run once)
  }
}
```

**Deploy JDBC connector:**
```bash
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d @jdbc-source-aurora-bulk-load.json

# Monitor bulk load progress
curl -s http://localhost:8083/connectors/jdbc-source-aurora-bulk-load/status | jq .
```

**Step 5: Deploy Debezium connector —Å snapshot.mode=never**

```json
{
  "name": "aurora-mysql-streaming-only",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "tasks.max": "1",

    // Connect to PRODUCTION writer (NOT restored cluster)
    "database.hostname": "my-aurora-cluster.cluster-abc123.us-east-1.rds.amazonaws.com",
    "database.port": "3306",
    "database.user": "debezium",
    "database.password": "${file:/secrets/mysql-password.txt:password}",
    "database.server.id": "184056",

    "database.include.list": "inventory",
    "table.include.list": "inventory.customers,inventory.orders,inventory.products",

    "topic.prefix": "aurora-mysql",

    // NO snapshot - data already loaded via JDBC connector
    "snapshot.mode": "never",

    // Schema history (MUST be populated or connector fails)
    "schema.history.internal.kafka.bootstrap.servers": "kafka:9092",
    "schema.history.internal.kafka.topic": "schema-history.aurora-mysql",

    // Skip unparseable DDL if schema history incomplete
    "database.history.skip.unparseable.ddl": "true",

    "heartbeat.interval.ms": "30000",
    "include.schema.changes": "true",

    "decimal.handling.mode": "precise",
    "time.precision.mode": "adaptive_time_microseconds"
  }
}
```

<Callout type="warning" title="Schema History Topic –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –ø—Ä–∏ snapshot.mode=never">

**–ü—Ä–æ–±–ª–µ–º–∞:** `snapshot.mode=never` –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ Debezium **–Ω–µ —á–∏—Ç–∞–µ—Ç schemas** –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö. Connector –ø–æ–ª–∞–≥–∞–µ—Ç—Å—è –Ω–∞ **schema.history.internal.kafka.topic** –¥–ª—è –≤–æ—Å—Å–æ–∑–¥–∞–Ω–∏—è schemas.

**–†–µ—à–µ–Ω–∏—è:**

**Option A: Populate schema history –≤—Ä—É—á–Ω—É—é (complex)**
```sql
-- Export DDL statements from production
mysqldump --no-data --databases inventory > schema.sql

-- Manually publish DDL to schema history topic (advanced)
```

**Option B: Run connector —Å snapshot.mode=schema_only ONCE, –∑–∞—Ç–µ–º recreate —Å snapshot.mode=never**
```bash
# First deployment: schema-only snapshot
# Deploy connector —Å "snapshot.mode": "schema_only"
# ‚Üí Schema history topic populated with DDL
# Delete connector

# Second deployment: streaming only
# Deploy connector —Å "snapshot.mode": "never"
# ‚Üí Uses schema history from first run
```

**Option C: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ initial snapshot (minimal mode) –µ—Å–ª–∏ bulk load –Ω–µ critical path**

</Callout>

**Deploy streaming connector:**
```bash
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d @aurora-mysql-streaming-only.json

# Verify connector starts from saved binlog position
docker compose logs debezium-connect | grep "mysql-bin-changelog.000005"
# Expected: "Starting streaming from mysql-bin-changelog.000005 at position 154"
```

**Step 6: Cleanup temporary cluster**

```bash
# After Debezium connector running successfully
# Delete restored cluster to save costs

# Delete instance
aws rds delete-db-instance \
  --db-instance-identifier aurora-restore-cdc-temp-instance-1 \
  --skip-final-snapshot \
  --region us-east-1

# Delete cluster
aws rds delete-db-cluster \
  --db-cluster-identifier aurora-restore-cdc-temp \
  --skip-final-snapshot \
  --region us-east-1

# Optionally delete snapshot if no longer needed
aws rds delete-db-cluster-snapshot \
  --db-cluster-snapshot-identifier aurora-cdc-baseline-2026-02-01 \
  --region us-east-1
```

### Backup-Based Approach: Pros & Cons

**Pros:**
- ‚úÖ **No locks** –Ω–∞ production database
- ‚úÖ **Faster bulk load** —á–µ—Ä–µ–∑ JDBC (parallel tasks, optimized batch reads)
- ‚úÖ **No schema freeze** requirement
- ‚úÖ **Minimal impact** –Ω–∞ production performance

**Cons:**
- ‚ùå **Complex setup** (Aurora snapshot + restore + JDBC connector + Debezium)
- ‚ùå **Cost:** Temporary Aurora cluster –º–æ–∂–µ—Ç —Å—Ç–æ–∏—Ç—å —Å–æ—Ç–Ω–∏ –¥–æ–ª–ª–∞—Ä–æ–≤ –≤ –¥–µ–Ω—å
- ‚ùå **Schema history management** —Ç—Ä–µ–±—É–µ—Ç manual steps –∏–ª–∏ schema_only snapshot
- ‚ùå **Time:** Snapshot creation (30-60 min) + restore (10-15 min) + bulk load (hours)

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
- –¢–∞–±–ª–∏—Ü—ã **500GB+**
- Zero lock tolerance
- Cannot freeze schema changes
- Cost –æ–±–æ—Å–Ω–æ–≤—ã–≤–∞–µ—Ç—Å—è business requirements (e.g., critical production system)

## –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ Snapshot Progress

### Connector logs: Snapshot phases

Debezium connector –ª–æ–≥–∏—Ä—É–µ—Ç snapshot –ø—Ä–æ–≥—Ä–µ—Å—Å —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–∑:

```bash
# Real-time logs from Debezium connector
docker compose logs -f debezium-connect | grep -E "(Snapshot|Locking)"

# Expected log sequence:
# INFO: Starting snapshot for connector aurora-mysql-connector
# INFO: Flush tables with read lock failed, falling back to table-level locks
# INFO: Acquiring table-level lock for inventory.customers
# INFO: Snapshot step 1 - Determining captured tables
# INFO: Snapshot step 2 - Locking captured tables [inventory.customers, inventory.orders]
# INFO: Snapshot step 3 - Reading structure of captured tables
# INFO: Snapshot step 4 - Releasing table locks
# INFO: Snapshot step 5 - Snapshotting data
# INFO: Snapshot - Scanned 10000 rows in 'inventory.customers'
# INFO: Snapshot - Scanned 50000 rows in 'inventory.orders'
# INFO: Snapshot completed successfully
```

**Key indicators:**
- `Acquiring table-level lock` ‚Üí Lock –Ω–∞—á–∞—Ç
- `Releasing table locks` ‚Üí Lock —Å–Ω—è—Ç (data reading –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è)
- `Scanned X rows` ‚Üí Progress for large tables
- `Snapshot completed` ‚Üí Success

### MySQL SHOW PROCESSLIST: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫

```sql
-- Connect to Aurora writer
mysql -h my-aurora-cluster.cluster-abc123.us-east-1.rds.amazonaws.com -u admin -p

-- Check active processes and locks
SHOW PROCESSLIST;
```

**Output interpretation:**

```
+-----+----------+-----------+------+---------+------+---------------------------+------------------------------+
| Id  | User     | Host      | db   | Command | Time | State                     | Info                         |
+-----+----------+-----------+------+---------+------+---------------------------+------------------------------+
| 123 | debezium | 10.0.1.50 | NULL | Query   | 45   | Waiting for table lock    | LOCK TABLES inventory.orders READ |
| 124 | app_user | 10.0.1.51 | inv  | Query   | 5    | Locked                    | INSERT INTO inventory.orders ... |
+-----+----------+-----------+------+---------+------+---------------------------+------------------------------+
```

**Indicators:**
- **`Waiting for table lock`**: Debezium –ø—ã—Ç–∞–µ—Ç—Å—è –ø–æ–ª—É—á–∏—Ç—å lock
- **`Locked`**: Application query –±–ª–æ–∫–∏—Ä—É–µ—Ç—Å—è Debezium snapshot
- **`Time` column**: Lock duration (—Å–µ–∫—É–Ω–¥—ã)

<Callout type="tip" title="–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ lock duration">

**Warning threshold:** –ï—Å–ª–∏ `Time > 300` —Å–µ–∫—É–Ω–¥ (5 –º–∏–Ω—É—Ç) –¥–ª—è table lock:

1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ table schema complexity:
   ```sql
   SELECT COUNT(*) AS column_count
   FROM INFORMATION_SCHEMA.COLUMNS
   WHERE table_schema = 'inventory' AND table_name = 'orders';
   ```

2. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–µ—Ä–µ—Ö–æ–¥ –Ω–∞ `snapshot.locking.mode=none` (—Å schema freeze)

3. –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ backup-based approach

</Callout>

### Kafka Connect REST API: Connector status

```bash
# Check connector status
curl -s http://localhost:8083/connectors/aurora-mysql-connector/status | jq .

# Expected during snapshot:
# {
#   "name": "aurora-mysql-connector",
#   "connector": {
#     "state": "RUNNING",
#     "worker_id": "connect:8083"
#   },
#   "tasks": [
#     {
#       "id": 0,
#       "state": "RUNNING",
#       "worker_id": "connect:8083"
#     }
#   ]
# }
```

**Metrics:**
```bash
# Connector metrics (snapshot progress)
curl -s http://localhost:8083/connectors/aurora-mysql-connector/status | \
  jq '.tasks[0].trace'

# If snapshot stuck, check for errors
```

### CloudWatch Metrics (Aurora-specific)

–î–ª—è Aurora MySQL –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ lock impact –Ω–∞ production:

- **`DatabaseConnections`**: Spike –º–æ–∂–µ—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ connection pileup –∏–∑-–∑–∞ locks
- **`WriteLatency`**: –£–≤–µ–ª–∏—á–µ–Ω–∏–µ latency –≤–æ –≤—Ä–µ–º—è snapshot (–µ—Å–ª–∏ `minimal` mode)
- **`DMLLatency`**: INSERT/UPDATE latency spike
- **`SelectLatency`**: Queries –±–ª–æ–∫–∏—Ä—É—é—Ç—Å—è table locks

**CloudWatch query example:**
```bash
# Via AWS CLI
aws cloudwatch get-metric-statistics \
  --namespace AWS/RDS \
  --metric-name WriteLatency \
  --dimensions Name=DBClusterIdentifier,Value=my-aurora-cluster \
  --start-time 2026-02-01T10:00:00Z \
  --end-time 2026-02-01T11:00:00Z \
  --period 60 \
  --statistics Average \
  --region us-east-1
```

## Troubleshooting: –¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã Snapshot

<table style={{fontSize: '0.9em'}}>
  <thead>
    <tr>
      <th>–ü—Ä–æ–±–ª–µ–º–∞</th>
      <th>–°–∏–º–ø—Ç–æ–º—ã</th>
      <th>Root Cause</th>
      <th>–†–µ—à–µ–Ω–∏–µ</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Access denied for FLUSH TABLES</strong></td>
      <td>
        Connector logs:<br/>
        <code>ERROR 1227: Access denied</code><br/>
        –ù–æ –∑–∞—Ç–µ–º:<br/>
        <code>Falling back to table-level locks</code>
      </td>
      <td>Aurora –Ω–µ —Ä–∞–∑—Ä–µ—à–∞–µ—Ç global lock (expected)</td>
      <td>
        ‚úÖ <strong>–≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ!</strong><br/>
        Debezium –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ fallback –Ω–∞ table locks.<br/>
        No action required.
      </td>
    </tr>
    <tr>
      <td><strong>Lock wait timeout exceeded</strong></td>
      <td>
        Connector logs:<br/>
        <code>Lock wait timeout exceeded; try restarting transaction</code>
      </td>
      <td>
        Table locks –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å –ø–æ–ª—É—á–µ–Ω—ã –∏–∑-–∑–∞:<br/>
        - Long-running queries<br/>
        - DDL –≤ progress
      </td>
      <td>
        1. –£–≤–µ–ª–∏—á–∏—Ç—å timeout:<br/>
        <code>"snapshot.query.timeout.ms": "600000"</code><br/>
        2. –ò–ª–∏ –ø–µ—Ä–µ–π—Ç–∏ –Ω–∞ <code>snapshot.locking.mode=none</code><br/>
        3. –ò–ª–∏ scheduler snapshot window (off-peak hours)
      </td>
    </tr>
    <tr>
      <td><strong>Schema changed during snapshot</strong></td>
      <td>
        Connector fails —Å:<br/>
        <code>Table structure changed</code><br/>
        –ò–ª–∏ consumer –≤–∏–¥–∏—Ç schema mismatch
      </td>
      <td>
        <code>snapshot.locking.mode=none</code> –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è,<br/>
        –Ω–æ DDL –≤—ã–ø–æ–ª–Ω–∏–ª—Å—è –≤–æ –≤—Ä–µ–º—è snapshot
      </td>
      <td>
        1. ‚ùå <strong>Restart snapshot</strong> (data inconsistency)<br/>
        2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ <code>minimal</code> mode (accept locks)<br/>
        3. –ò–ª–∏ implement schema freeze window
      </td>
    </tr>
    <tr>
      <td><strong>Snapshot taking too long</strong></td>
      <td>
        Snapshot running for hours/days<br/>
        Production writes degraded
      </td>
      <td>
        Very large tables (100GB+)<br/>
        Network bandwidth limited
      </td>
      <td>
        1. Switch to <code>snapshot.locking.mode=none</code><br/>
        2. Or use <strong>backup-based approach</strong> (—Ä–∞–∑–¥–µ–ª 7)<br/>
        3. Or incremental snapshot via signal table
      </td>
    </tr>
    <tr>
      <td><strong>Connector fails: "db history topic missing"</strong></td>
      <td>
        <code>snapshot.mode=never</code> fails:<br/>
        <code>The db history topic or its content is fully or partially missing</code>
      </td>
      <td>
        Schema history topic –Ω–µ populated<br/>
        (required for <code>snapshot.mode=never</code>)
      </td>
      <td>
        1. Run connector —Å <code>snapshot.mode=schema_only</code> first<br/>
        2. Then recreate —Å <code>snapshot.mode=never</code><br/>
        3. Or manually populate schema history topic
      </td>
    </tr>
    <tr>
      <td><strong>Production writes blocked during snapshot</strong></td>
      <td>
        Application timeouts<br/>
        <code>SHOW PROCESSLIST</code> shows Locked state
      </td>
      <td>
        <code>snapshot.locking.mode=minimal</code><br/>
        Table locks held too long (complex schema)
      </td>
      <td>
        1. Monitor lock duration via <code>SHOW PROCESSLIST</code><br/>
        2. If &gt; 5 minutes ‚Üí switch to <code>none</code> mode or backup-based<br/>
        3. Schedule snapshot during maintenance window
      </td>
    </tr>
  </tbody>
</table>

### –ö–æ–≥–¥–∞ restart snapshot –ø–æ—Å–ª–µ failure?

**–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π restart:** Debezium connector –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç snapshot –µ—Å–ª–∏:
- Connector crashes –≤–æ –≤—Ä–µ–º—è snapshot
- Kafka Connect worker restarts
- Network timeout

**Manual restart required:**
```bash
# Restart connector (triggers snapshot from beginning)
curl -X POST http://localhost:8083/connectors/aurora-mysql-connector/restart

# Or delete and recreate connector
curl -X DELETE http://localhost:8083/connectors/aurora-mysql-connector
# Then redeploy
curl -X POST http://localhost:8083/connectors -H "Content-Type: application/json" -d @connector-config.json
```

<Callout type="warning" title="Restart snapshot = start from beginning">

Debezium **–Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç resumable snapshots** (–∫—Ä–æ–º–µ incremental snapshot via signal table).

–ï—Å–ª–∏ snapshot –ø—Ä–µ—Ä—ã–≤–∞–µ—Ç—Å—è:
- Data —É–∂–µ sent to Kafka ‚Üí remains (–º–æ–∂–µ—Ç –±—ã—Ç—å duplicates)
- Offset not committed ‚Üí connector restarts snapshot from scratch
- –î–ª—è 500GB tables ‚Üí potentially hours/days lost

**Mitigation:**
- Use incremental snapshot (Debezium 1.6+) –¥–ª—è resumable snapshots
- Or backup-based approach –¥–ª—è –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü

</Callout>

## Key Takeaways

**1. Aurora MySQL –∑–∞–ø—Ä–µ—â–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏**
- `FLUSH TABLES WITH READ LOCK` –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ Aurora (managed service security)
- Debezium –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ fallback –Ω–∞ table-level locks
- –≠—Ç–æ expected behavior, –Ω–µ –æ—à–∏–±–∫–∞

**2. –í—ã–±–æ—Ä snapshot.locking.mode –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ —Ç–∞–±–ª–∏—Ü**
- **< 100 GB**: `minimal` mode (safe default, –∫—Ä–∞—Ç–∫–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ locks)
- **> 100 GB + zero lock tolerance**: `none` mode (–¢–†–ï–ë–£–ï–¢ schema freeze)
- **500GB+**: Backup-based approach (Aurora snapshot + JDBC bulk load + Debezium streaming)

**3. snapshot.locking.mode=none –æ–ø–∞—Å–µ–Ω –±–µ–∑ schema freeze**
- DDL statement –≤–æ –≤—Ä–µ–º—è snapshot ‚Üí data inconsistency
- –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ coordinate —Å –∫–æ–º–∞–Ω–¥–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
- –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `minimal` mode (accept locks)

**4. Backup-based approach –¥–ª—è enterprise use cases**
- Zero locks –Ω–∞ production
- Faster –¥–ª—è –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü
- –ù–æ complex setup –∏ cost (temporary Aurora cluster)

**5. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ snapshot progress –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω**
- Connector logs: snapshot phases
- MySQL SHOW PROCESSLIST: lock duration
- CloudWatch: WriteLatency, DMLLatency impact

**6. Troubleshooting checklist**
- "Access denied for FLUSH TABLES" ‚Üí Expected, automatic fallback
- "Lock wait timeout" ‚Üí Increase timeout –∏–ª–∏ switch to `none` mode
- "Schema changed during snapshot" ‚Üí Restart snapshot, use `minimal` mode, or implement freeze
- "Snapshot too long" ‚Üí Backup-based approach

## –ü—Ä–∞–∫—Ç–∏–∫–∞: Hands-On Exercise

–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å Debezium connector –¥–ª—è Aurora MySQL —Å —Ä–∞–∑–Ω—ã–º–∏ snapshot modes:

**Exercise 1: Minimal mode (safe default)**
1. Deploy connector —Å `snapshot.locking.mode=minimal`
2. Monitor lock duration via `SHOW PROCESSLIST`
3. Verify snapshot completes successfully

**Exercise 2: None mode (advanced, schema freeze required)**
1. Coordinate schema freeze window (no DDL allowed)
2. Deploy connector —Å `snapshot.locking.mode=none`
3. Monitor for DDL statements during snapshot (should be zero)
4. Verify data consistency after snapshot

**Exercise 3: Backup-based approach (enterprise)**
1. Capture binlog position via `SHOW MASTER STATUS`
2. Create Aurora DB cluster snapshot
3. Restore to temporary cluster
4. Bulk load via JDBC source connector
5. Deploy Debezium with `snapshot.mode=never`
6. Verify streaming from saved binlog position

**Advanced Exercise: Simulate schema change during snapshot**
1. Start snapshot —Å `snapshot.locking.mode=none`
2. Execute `ALTER TABLE` –≤–æ –≤—Ä–µ–º—è snapshot
3. Observe data inconsistency in Kafka topics
4. Restart snapshot —Å `minimal` mode
5. Verify consistency

## –ß—Ç–æ –¥–∞–ª—å—à–µ?

–í —Å–ª–µ–¥—É—é—â–µ–º —É—Ä–æ–∫–µ **"Aurora MySQL Production Operations"** –º—ã –∏–∑—É—á–∏–º:
- Monitoring Aurora MySQL CDC –≤ production
- Failover scenarios (writer instance failover)
- Binlog retention management –¥–ª—è Aurora
- Enhanced Binlog monitoring (ChangeLogBytesUsed, ChangeLogIOPs)
- Disaster recovery strategies

**–ú–æ–¥—É–ª—å 8 roadmap:**
- ‚úÖ Lesson 1-6: MySQL binlog, GTID, retention, connector config
- ‚úÖ Lesson 7: Aurora parameter groups
- ‚úÖ Lesson 8: Enhanced Binlog architecture
- ‚úÖ **Lesson 9: Aurora snapshot modes** ‚Üê –í—ã –∑–¥–µ—Å—å
- üîú Lesson 10: Aurora production operations
- üîú Lesson 11: MySQL/Aurora comparison & decision matrix
